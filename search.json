[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "data_analysis.html",
    "href": "data_analysis.html",
    "title": "Job Market Analysis Group 3",
    "section": "",
    "text": "from pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\nimport plotly.io as pio\nimport numpy as np\n\nnp.random.seed(42)\n\npio.renderers.default = \"notebook\"\n\n# Initialize Spark Session\nspark = SparkSession.builder.appName(\"LightcastData\").getOrCreate()\n\n# Load Data\ndf = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\",\"true\").option(\"escape\", \"\\\"\").csv(\"../data/lightcast_job_postings.csv\")\n\n# Show Schema and Sample Data\nprint(\"---This is Diagnostic check, No need to print it in the final doc---\")\n\ndf.printSchema() # comment this line when rendering the submission\ndf.show(5)\n\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n25/06/19 17:41:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[1], line 12\n      9 pio.renderers.default = \"notebook\"\n     11 # Initialize Spark Session\n---&gt; 12 spark = SparkSession.builder.appName(\"LightcastData\").getOrCreate()\n     14 # Load Data\n     15 df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\",\"true\").option(\"escape\", \"\\\"\").csv(\"../data/lightcast_job_postings.csv\")\n\nFile ~/AD688-GROUP3-JOB-MARKET-ANALYSIS-2/.venv/lib/python3.12/site-packages/pyspark/sql/session.py:559, in SparkSession.Builder.getOrCreate(self)\n    556     sc = SparkContext.getOrCreate(sparkConf)\n    557     # Do not update `SparkConf` for existing `SparkContext`, as it's shared\n    558     # by all sessions.\n--&gt; 559     session = SparkSession(sc, options=self._options)\n    560 else:\n    561     module = SparkSession._get_j_spark_session_module(session._jvm)\n\nFile ~/AD688-GROUP3-JOB-MARKET-ANALYSIS-2/.venv/lib/python3.12/site-packages/pyspark/sql/session.py:635, in SparkSession.__init__(self, sparkContext, jsparkSession, options)\n    631 jSparkSessionModule = SparkSession._get_j_spark_session_module(self._jvm)\n    633 if jsparkSession is None:\n    634     if (\n--&gt; 635         jSparkSessionClass.getDefaultSession().isDefined()\n    636         and not jSparkSessionClass.getDefaultSession().get().sparkContext().isStopped()\n    637     ):\n    638         jsparkSession = jSparkSessionClass.getDefaultSession().get()\n    639         jSparkSessionModule.applyModifiableSettings(jsparkSession, options)\n\nTypeError: 'JavaPackage' object is not callable"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Job Market Analysis Group 3",
    "section": "",
    "text": "Job Market in US for Data Analytics graduate is booming. This analysis is our project to expolre the career posibilities after graduation."
  },
  {
    "objectID": "index.html#history",
    "href": "index.html#history",
    "title": "Job Market Analysis Group 3",
    "section": "",
    "text": "Job Market in US for Data Analytics graduate is booming. This analysis is our project to expolre the career posibilities after graduation."
  }
]